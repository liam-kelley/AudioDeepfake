# This config file is the an edited version of the default hifigan cfg file for use with M. cruise.
# I added the model.train_ds dataloader options...

name: "HifiGan"

init_from_pretrained_model : "tts_hifigan"

train_dataset: "./manifests/manifest_hifigan_train.json"
validation_datasets: "./manifests/manifest_hifigan_val.json"

sup_data_path: "./hifigan_sup_data"
sup_data_types: [ "align_prior_matrix", "pitch"]

# Default values from librosa.pyin
pitch_fmin: 65.40639132514966
pitch_fmax: 2093.004522404789

pitch_mean: 100.3  # e.g. 212.35873413085938 for LJSpeech
pitch_std:  64  # e.g.  68.52806091308594 for LJSpeech

# Default values for dataset with sample_rate=22050
sample_rate: 22050
n_mel_channels: 80
n_window_size: 1024
n_window_stride: 256
n_fft: 1024
lowfreq: 0
highfreq: 8000
window: hann

train_n_segments: 8192
train_max_duration: null
train_min_duration: 0.75

val_n_segments: 66048
val_max_duration: null
val_min_duration: 3

phoneme_dict_path: "tts_dataset_files/cmudict-0.7b_nv22.10"
heteronyms_path: "tts_dataset_files/heteronyms-052722"
whitelist_path: "tts_dataset_files/tts.tsv"

model:
  generator: 
    _target_: nemo.collections.tts.modules.hifigan_modules.Generator
    resblock: 1
    upsample_rates: [8,8,2,2]
    upsample_kernel_sizes: [16,16,4,4]
    upsample_initial_channel: 512
    resblock_kernel_sizes: [3,7,11]
    resblock_dilation_sizes: [[1,3,5], [1,3,5], [1,3,5]]

  train_ds:
    dataset:
      _target_: "nemo.collections.tts.torch.data.VocoderDataset"
      manifest_filepath: ${train_dataset}
      sample_rate: ${sample_rate}
      n_segments: ${train_n_segments}
      max_duration: ${train_max_duration}
      min_duration: ${train_min_duration}
      load_precomputed_mel: true
      hop_length: ${n_window_stride}
    dataloader_params:
      drop_last: false
      shuffle: true
      batch_size: 16
      num_workers: 4
      pin_memory: true
  
  validation_ds:
    dataset:
      _target_: "nemo.collections.tts.torch.data.VocoderDataset"
      manifest_filepath: ${validation_datasets}
      sample_rate: ${sample_rate}
      n_segments: ${val_n_segments}
      max_duration: ${val_max_duration}
      min_duration: ${val_min_duration}
      load_precomputed_mel: true
      hop_length: ${n_window_stride}
    dataloader_params:
      drop_last: false
      shuffle: false
      batch_size: 16
      num_workers: 4
      pin_memory: true

  preprocessor:
    _target_: nemo.collections.asr.parts.preprocessing.features.FilterbankFeatures
    nfilt: ${n_mel_channels}
    lowfreq: ${lowfreq}
    highfreq: ${highfreq}
    n_fft: ${n_fft}
    n_window_size: ${n_window_size}
    n_window_stride: ${n_window_stride}
    pad_to: 0
    pad_value: -11.52
    sample_rate: ${sample_rate}
    window: ${window}
    normalize: null
    preemph: null
    dither: 0.0
    frame_splicing: 1
    log: true
    log_zero_guard_type: clamp
    log_zero_guard_value: 1e-05
    mag_power: 1.0
    use_grads: false
    exact_pad: true

  optim:
    _target_: torch.optim.AdamW
    lr: 0.00001
    betas: [0.8, 0.99]

  max_steps: 10000
  l1_loss_factor: 45
  denoise_strength: 0.0025

trainer:
  num_nodes: 1
  devices: 1
  accelerator: gpu
  strategy: ddp
  precision: 32
  max_steps: ${model.max_steps}
  accumulate_grad_batches: 1
  enable_checkpointing: False  # Provided by exp_manager
  logger: false # Provided by exp_manager
  log_every_n_steps: 10
  check_val_every_n_epoch: 5
  benchmark: false

exp_manager:
  exp_dir: "./exp/hifigan_cruisetuningv1"
  name: ${name}
  create_tensorboard_logger: true
  create_checkpoint_callback: true
  checkpoint_callback_params:
    monitor: val_loss
    mode: min
  create_wandb_logger: false
  wandb_logger_kwargs:
    name: null
    project: null
    entity: null
  resume_if_exists: false
  resume_ignore_no_checkpoint: false
